{
  "name": "torch_starter-cuda (PyTorch 2.8.0, CUDA 12.9, UV, System Python)",
  "build": {
    "dockerfile": "Dockerfile",
    "context": "..",
    "options": [
      "--build-arg",
      "BUILDKIT_INLINE_CACHE=1",
      "--build-arg",
      "CUDA_VERSION=12.9"
    ]
  },
  "runArgs": [
    "--gpus",
    "all",
    "--shm-size=8g",
    "--ulimit",
    "memlock=-1",
    "--ulimit",
    "stack=67108864",
    "--cap-add",
    "SYS_PTRACE",
    "--security-opt",
    "seccomp=unconfined",
    "--ipc=host"
  ],
  "containerUser": "ubuntu",
  "workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}",
  "containerEnv": {
    "HF_HOME": "/home/ubuntu/.cache/huggingface",
    "TRANSFORMERS_CACHE": "/home/ubuntu/.cache/huggingface",
    "TORCH_HOME": "/home/ubuntu/.cache/torch",
    "KAGGLE_CONFIG_DIR": "/home/ubuntu/.kaggle",
    "UV_LINK_MODE": "copy",
    "UV_COMPILE_BYTECODE": "1",
    "UV_CONCURRENT_DOWNLOADS": "20",
    "UV_HTTP_TIMEOUT": "600",
    "UV_SYSTEM_PYTHON": "1",
    "UV_PYTHON_DOWNLOADS": "never",
    "PYTHONDONTWRITEBYTECODE": "1",
    "PYTHONUNBUFFERED": "1",
    "PYTHONOPTIMIZE": "1",
    "CUDA_VERSION": "12.9",
    "CUDA_VISIBLE_DEVICES": "all",
    "NVIDIA_VISIBLE_DEVICES": "all",
    "NVIDIA_DRIVER_CAPABILITIES": "compute,utility",
    "NVIDIA_REQUIRE_CUDA": "cuda>=12.9",
    "TORCH_CUDA_ARCH_LIST": "7.0;7.5;8.0;8.6;8.9;9.0",
    "FORCE_CUDA": "1",
    "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:512,garbage_collection_threshold:0.6",
    "CUDA_LAUNCH_BLOCKING": "0",
    "MALLOC_ARENA_MAX": "2"
  },
  "mounts": [
    {
      "source": "torch-starter-hf-cache",
      "target": "/home/ubuntu/.cache/huggingface",
      "type": "volume"
    },
    {
      "source": "torch-starter-torch-cache",
      "target": "/home/ubuntu/.cache/torch",
      "type": "volume"
    },
    {
      "source": "torch-starter-kaggle-cache",
      "target": "/home/ubuntu/.kaggle",
      "type": "volume"
    },
    {
      "source": "torch-starter-data",
      "target": "/workspaces/${localWorkspaceFolderBasename}/data",
      "type": "volume"
    },
    {
      "source": "torch-starter-uv-cache",
      "target": "/home/ubuntu/.cache/uv",
      "type": "volume"
    },
    {
      "source": "torch-starter-pip-cache",
      "target": "/home/ubuntu/.cache/pip",
      "type": "volume"
    },
    {
      "source": "torch-starter-models",
      "target": "/home/ubuntu/.cache/models",
      "type": "volume"
    }
  ],
  "initializeCommand": [
    "bash",
    "-c",
    "echo '🏗️  Initializing Docker volumes...' && docker volume create torch-starter-hf-cache 2>/dev/null || true; docker volume create torch-starter-torch-cache 2>/dev/null || true; docker volume create torch-starter-kaggle-cache 2>/dev/null || true; docker volume create torch-starter-data 2>/dev/null || true; docker volume create torch-starter-uv-cache 2>/dev/null || true; docker volume create torch-starter-pip-cache 2>/dev/null || true; docker volume create torch-starter-models 2>/dev/null || true; echo '✅ Docker volumes ready'"
  ],
  "features": {
    "ghcr.io/devcontainers/features/common-utils:2": {
      "configureZshAsDefaultShell": true,
      "upgradePackages": false
    },
    "ghcr.io/devcontainers/features/git:1": {
      "ppa": false,
      "version": "os-provided"
    }
  },
  "postCreateCommand": {
    "activate-env": "bash -c 'echo \"🐍 Using system Python with UV...\" && python -c \"import sys; print(f\\\"✅ Python {sys.version}\\\")\" && python -c \"import torch; print(f\\\"🔥 PyTorch {torch.__version__}\\\"); print(f\\\"🚀 CUDA Available: {torch.cuda.is_available()}\\\"); print(f\\\"📱 CUDA Devices: {torch.cuda.device_count()}\\\") if torch.cuda.is_available() else print(\\\"⚠️  CUDA Not Available\\\"); import transformers; print(f\\\"🤗 Transformers {transformers.__version__}\\\")\" && uv --version && echo \"📦 UV Package Manager ready\"'",
    "setup-git": "git config --global --add safe.directory /workspaces/${localWorkspaceFolderBasename}",
    "verify-cuda": "bash -c 'if command -v nvidia-smi >/dev/null 2>&1; then echo \"🖥️  GPU Information:\"; nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv,noheader; echo \"📊 GPU Driver Info:\"; nvidia-smi --query-gpu=driver_version --format=csv,noheader; else echo \"⚠️  nvidia-smi not available - GPU may not be accessible\"; fi'",
    "setup-aliases": "echo 'alias gpu-monitor=\"watch -n 1 \\\"nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv\\\"\"' >> ~/.bashrc && echo 'alias gpu-info=\"nvidia-smi --query-gpu=name,memory.total,compute_cap,driver_version --format=csv\"' >> ~/.bashrc && echo 'alias torch-info=\"python -c \\\"import torch; print(f\\\"PyTorch: {torch.__version__}\\\"); print(f\\\"CUDA: {torch.version.cuda}\\\"); print(f\\\"cuDNN: {torch.backends.cudnn.version()}\\\"); print(f\\\"Devices: {torch.cuda.device_count()}\\\")\\\"\"' >> ~/.bashrc && echo 'alias uv-install=\"uv pip install --system\"' >> ~/.bashrc && echo 'alias uv-list=\"uv pip list --system\"' >> ~/.bashrc && echo 'alias uv-sync=\"uv pip sync --system\"' >> ~/.bashrc"
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-python.vscode-pylance",
        "ms-toolsai.jupyter",
        "charliermarsh.ruff",
        "eamodio.gitlens",
        "EditorConfig.EditorConfig",
        "ms-azuretools.vscode-docker",
        "RooVeterinaryInc.roo-cline",
        "mechatroner.rainbow-csv",
        "gaogaotiantian.viztracer-vscode",
        "bierner.markdown-mermaid",
        "ms-toolsai.vscode-ai-remote",
        "GitHub.copilot",
        "ms-python.debugpy",
        "ms-vscode.vscode-json"
      ],
      "settings": {
        "python.defaultInterpreterPath": "/opt/conda/bin/python",
        "python.terminal.activateEnvironment": false,
        "python.analysis.typeCheckingMode": "basic",
        "python.analysis.autoImportCompletions": true,
        "python.analysis.indexing": true,
        "python.analysis.packageIndexDepths": [
          {
            "name": "sklearn",
            "depth": 2
          },
          {
            "name": "torch",
            "depth": 3
          },
          {
            "name": "transformers",
            "depth": 2
          },
          {
            "name": "datasets",
            "depth": 2
          }
        ],
        "python.testing.pytestEnabled": true,
        "python.testing.unittestEnabled": false,
        "python.testing.pytestArgs": [
          "tests"
        ],
        "ruff.enable": true,
        "ruff.organizeImports": true,
        "ruff.serverEnabled": true,
        "ruff.lint.enable": true,
        "ruff.format.enable": true,
        "files.watcherExclude": {
          "**/.venv/**": true,
          "**/__pycache__/**": true,
          "**/.mypy_cache/**": true,
          "**/.ruff_cache/**": true,
          "**/.pytest_cache/**": true,
          "**/node_modules/**": true,
          "**/.cache/**": true,
          "**/data/**": true,
          "**/logs/**": true,
          "**/*.log": true
        },
        "search.exclude": {
          "**/__pycache__": true,
          "**/.mypy_cache": true,
          "**/.ruff_cache": true,
          "**/.cache": true,
          "**/data": true,
          "**/logs": true
        },
        "files.exclude": {
          "**/__pycache__": true,
          "**/.mypy_cache": true,
          "**/.ruff_cache": true,
          "**/.pytest_cache": true
        },
        "terminal.integrated.defaultProfile.linux": "zsh",
        "terminal.integrated.shellIntegration.enabled": true,
        "terminal.integrated.env.linux": {
          "CUDA_VISIBLE_DEVICES": "all",
          "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:512,garbage_collection_threshold:0.6",
          "UV_SYSTEM_PYTHON": "1",
          "UV_PYTHON_DOWNLOADS": "never"
        },
        "jupyter.askForKernelRestart": false,
        "jupyter.defaultKernel": "torch_starter-3.11",
        "notebook.experimental.openGettingStarted": false,
        "notebook.kernelProviderAssociations": [
          {
            "viewType": "jupyter-notebook",
            "kernelspec": "torch_starter-3.11"
          }
        ],
        "git.enableSmartCommit": true,
        "git.autofetch": true,
        "extensions.autoUpdate": false,
        "telemetry.telemetryLevel": "off",
        "editor.formatOnSave": true,
        "editor.codeActionsOnSave": {
          "source.organizeImports.ruff": "explicit",
          "source.fixAll.ruff": "explicit"
        },
        "editor.rulers": [
          88,
          100
        ],
        "workbench.colorTheme": "Default Dark+",
        "workbench.preferredDarkColorTheme": "Default Dark+",
        "workbench.preferredLightColorTheme": "Default Light+",
        "[python]": {
          "editor.defaultFormatter": "charliermarsh.ruff",
          "editor.codeActionsOnSave": {
            "source.organizeImports": "explicit",
            "source.fixAll": "explicit"
          },
          "editor.formatOnSave": true
        },
        "[json]": {
          "editor.defaultFormatter": "vscode.json-language-features"
        },
        "[jsonc]": {
          "editor.defaultFormatter": "vscode.json-language-features"
        },
        "[dockerfile]": {
          "editor.defaultFormatter": "ms-azuretools.vscode-docker"
        },
        "debug.console.fontSize": 14,
        "debug.internalConsoleOptions": "openOnSessionStart",
        "python.analysis.diagnosticMode": "workspace"
      }
    }
  },
  "remoteEnv": {
    "ROO_CONFIG_PATH": "/workspaces/${localWorkspaceFolderBasename}/.roo/roo.json",
    "MCP_SERVERS_CONFIG": "/workspaces/${localWorkspaceFolderBasename}/.mcp/servers.json",
    "CUDA_VISIBLE_DEVICES": "all",
    "UV_SYSTEM_PYTHON": "1",
    "UV_PYTHON_DOWNLOADS": "never"
  },
  "shutdownAction": "stopContainer",
  "hostRequirements": {
    "gpu": "optional",
    "memory": "16gb",
    "cpus": 8,
    "storage": "50gb"
  },
  "capAdd": [
    "SYS_PTRACE"
  ],
  "securityOpt": [
    "seccomp=unconfined"
  ],
  "onCreateCommand": "echo '🏗️  Container created successfully - Setting up PyTorch 2.8.0 + CUDA 12.9 with UV and system Python...'",
  "updateContentCommand": "echo '🔄 Content updated - Verifying system Python environment...' && python -c 'import torch; print(f\"✅ Environment ready - PyTorch {torch.__version__} CUDA: {torch.cuda.is_available()}\")' && uv --version",
  "postStartCommand": "echo '🚀 Development environment ready with UV!' && echo '💡 Use \"gpu-monitor\" to monitor GPU usage' && echo '💡 Use \"torch-info\" to check PyTorch CUDA status' && echo '💡 Use \"uv-install <package>\" to install packages with UV'",
  "waitFor": "postCreateCommand"
}