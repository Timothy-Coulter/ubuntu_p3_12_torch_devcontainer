# .env.example - Copy to .env.local and customize with your actual credentials
# This file is safe to commit to git - contains only examples/templates

# ========================
# HUGGING FACE CONFIGURATION
# ========================
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=hf_your_token_here
HF_HOME=/home/vscode/.cache/huggingface
TRANSFORMERS_CACHE=/home/vscode/.cache/huggingface

# ========================
# KAGGLE CONFIGURATION  
# ========================
# Get credentials from: https://www.kaggle.com/settings/account > API > Create New Token
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_api_key
KAGGLE_CONFIG_DIR=/home/vscode/.kaggle

# ========================
# WEIGHTS & BIASES (WANDB)
# ========================
# Get API key from: https://wandb.ai/settings
WANDB_API_KEY=your_wandb_api_key
WANDB_PROJECT=your_default_project_name

# ========================
# OPENAI CONFIGURATION
# ========================
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_openai_api_key
OPENAI_ORG_ID=org-your_org_id_optional

# ========================
# ANTHROPIC CONFIGURATION
# ========================
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key

# ========================
# GOOGLE AI CONFIGURATION  
# ========================
# Get API key from: https://makersuite.google.com/app/apikey
GOOGLE_AI_API_KEY=your_google_ai_api_key

# ========================
# DEVELOPMENT SETTINGS
# ========================
# Environment type (development, staging, production)
ENVIRONMENT=development

# Debug mode (true/false)
DEBUG=true

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# ========================
# JUPYTER CONFIGURATION
# ========================
# Custom Jupyter token (leave empty to auto-generate secure token)
JUPYTER_TOKEN=

# Jupyter port (default: 8888)
JUPYTER_PORT=8888

# ========================
# DATA & MODEL PATHS
# ========================
# Root directory for datasets
DATA_DIR=/workspaces/torch_starter/data

# Model checkpoints directory
MODEL_DIR=/workspaces/torch_starter/data/models

# Output/results directory
OUTPUT_DIR=/workspaces/torch_starter/outputs

# ========================
# PERFORMANCE SETTINGS
# ========================
# Number of workers for data loading
NUM_WORKERS=4

# CUDA device visibility (all, 0,1,2,3, etc.)
CUDA_VISIBLE_DEVICES=all

# PyTorch CUDA memory allocation
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# ========================
# USAGE INSTRUCTIONS
# ========================
# 1. Copy this file to .env.local:
#    cp .env.example .env.local
#
# 2. Edit .env.local with your actual credentials
#    nano .env.local
#
# 3. The .env.local file is automatically ignored by git
#
# 4. Load in your application:
#    from dotenv import load_dotenv
#    load_dotenv('.env.local')
#
# 5. Or source in your shell:
#    export $(grep -v '^#' .env.local | xargs)
#
# 6. Use the setup script for interactive configuration:
#    ./dev.sh setup-keys